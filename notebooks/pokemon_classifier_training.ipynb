{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokemon Classifier Training Notebook\n",
    "\n",
    "Train a MobileNetV3-based classifier to identify Gen 1 Pokemon (151 classes).\n",
    "\n",
    "**Run this notebook in Google Colab for GPU acceleration.**\n",
    "\n",
    "**Note:** This notebook uses local Colab storage. Files will not persist between sessions.\n",
    "Make sure to download your trained model before the session ends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 1. Setup and Configuration\n#@markdown Install dependencies and configure paths (no Google Drive required)\n\n# Install TensorFlow and Kaggle first\n!pip install -q tensorflow kaggle\n\n# Upgrade packaging to satisfy Colab's pre-installed packages (bigquery, xarray, etc.)\n!pip install -q --upgrade packaging\n\n# Install tensorflowjs with --no-deps to avoid packaging version conflict\n# (tensorflowjs requires packaging~=23.1 but Colab needs >=24.x)\n# The actual runtime dependencies are already satisfied by tensorflow\n!pip install -q --no-deps tensorflowjs\n\n# Configuration\nCONFIG = {\n    # Paths (local Colab storage - does not persist between sessions)\n    'data_dir': '/content/data',\n    'models_dir': '/content/models',\n    \n    # Dataset\n    'kaggle_dataset': 'lantian773030/pokemonclassification',\n    \n    # Image settings\n    'image_size': 224,\n    'batch_size': 32,\n    \n    # Training\n    'epochs_frozen': 10,\n    'epochs_unfrozen': 15,\n    'learning_rate_frozen': 1e-3,\n    'learning_rate_unfrozen': 1e-5,\n    'dropout_rate': 0.5,\n    'validation_split': 0.15,\n    'test_split': 0.15,\n    \n    # Fine-tuning\n    'unfreeze_layers': 20,\n    \n    # Augmentation\n    'rotation_range': 20,\n    'zoom_range': 0.15,\n    'horizontal_flip': True,\n    \n    # Callbacks\n    'early_stopping_patience': 5,\n    'reduce_lr_patience': 3,\n}\n\nimport os\nos.makedirs(CONFIG['data_dir'], exist_ok=True)\nos.makedirs(CONFIG['models_dir'], exist_ok=True)\n\nprint(\"Configuration complete\")\nprint(f\"  Data directory: {CONFIG['data_dir']}\")\nprint(f\"  Models directory: {CONFIG['models_dir']}\")\nprint(\"\")\nprint(\"IMPORTANT: Files are stored locally and will be deleted when the session ends.\")\nprint(\"Make sure to download your trained model before disconnecting!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Download Dataset from Kaggle\n#@markdown Enter your Kaggle credentials below (Get from: https://www.kaggle.com/settings/account â†’ API)\n#@markdown\n#@markdown **OR** skip this cell and run Cell 2b to generate a fresh official dataset from PokeAPI\n\nKAGGLE_USERNAME = \"\"  #@param {type:\"string\"}\nKAGGLE_KEY = \"\"  #@param {type:\"string\"}\n\nimport os\nfrom pathlib import Path\nimport json\n\n# Check if dataset already exists\ndata_path = Path(CONFIG['data_dir'])\nexisting_dirs = list(data_path.glob(\"*/\"))\n\nif len(existing_dirs) > 100:\n    print(f\"Dataset already downloaded ({len(existing_dirs)} directories found)\")\nelse:\n    # Validate credentials\n    if not KAGGLE_USERNAME or not KAGGLE_KEY:\n        print(\"ERROR: Please fill in your Kaggle credentials above!\")\n        print(\"\")\n        print(\"How to get your credentials:\")\n        print(\"  1. Go to https://www.kaggle.com/settings/account\")\n        print(\"  2. Scroll to 'API' section\")\n        print(\"  3. Click 'Create New Token'\")\n        print(\"  4. Download kaggle.json file\")\n        print(\"  5. Open it and copy the username and key values\")\n        print(\"  6. Paste them into KAGGLE_USERNAME and KAGGLE_KEY above\")\n        print(\"\")\n        print(\"ALTERNATIVE: Skip this cell and run Cell 2b to generate\")\n        print(\"             a fresh dataset from official PokeAPI sources!\")\n        raise ValueError(\"Kaggle credentials required\")\n    \n    # Create Kaggle credentials\n    os.makedirs('/root/.kaggle', exist_ok=True)\n    kaggle_json = {\n        \"username\": KAGGLE_USERNAME,\n        \"key\": KAGGLE_KEY\n    }\n    \n    with open('/root/.kaggle/kaggle.json', 'w') as f:\n        json.dump(kaggle_json, f)\n    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n    \n    print(\"Kaggle credentials configured\")\n    print(f\"  Username: {KAGGLE_USERNAME}\")\n    print(\"\")\n    \n    # Download dataset\n    print(\"Downloading dataset...\")\n    !kaggle datasets download -d {CONFIG['kaggle_dataset']} -p {CONFIG['data_dir']} --unzip\n    \n    print(\"Dataset downloaded\")\n\n# Verify dataset\ndef count_images(directory):\n    count = 0\n    for root, dirs, files in os.walk(directory):\n        count += len([f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n    return count\n\ntotal_images = count_images(CONFIG['data_dir'])\nprint(f\"  Total images: {total_images}\")"
  },
  {
   "cell_type": "code",
   "source": "#@title 2b. Generate Official Dataset (Alternative to Kaggle)\n#@markdown **ALTERNATIVE**: Generate a fresh dataset from official PokeAPI sources\n#@markdown\n#@markdown This downloads official Pokemon sprites and artwork, then augments them\n#@markdown to create a high-quality training dataset. No Kaggle credentials needed!\n#@markdown\n#@markdown Benefits:\n#@markdown - Clean, verified labels (from official Pokemon API)\n#@markdown - Multiple sprite variants (official artwork, game sprites, shiny forms)\n#@markdown - Consistent image quality\n#@markdown - ~6000+ images after augmentation\n\nimport os\nimport sys\nimport time\nimport json\nimport hashlib\nimport requests\nfrom pathlib import Path\nfrom io import BytesIO\n\n# Install Pillow for image processing\n!pip install -q Pillow\n\nfrom PIL import Image, ImageEnhance, ImageFilter, ImageOps\nimport random\n\n# Gen 1 Pokemon list (151 Pokemon)\nGEN1_POKEMON = [\n    \"bulbasaur\", \"ivysaur\", \"venusaur\", \"charmander\", \"charmeleon\", \"charizard\",\n    \"squirtle\", \"wartortle\", \"blastoise\", \"caterpie\", \"metapod\", \"butterfree\",\n    \"weedle\", \"kakuna\", \"beedrill\", \"pidgey\", \"pidgeotto\", \"pidgeot\",\n    \"rattata\", \"raticate\", \"spearow\", \"fearow\", \"ekans\", \"arbok\",\n    \"pikachu\", \"raichu\", \"sandshrew\", \"sandslash\", \"nidoran-f\", \"nidorina\",\n    \"nidoqueen\", \"nidoran-m\", \"nidorino\", \"nidoking\", \"clefairy\", \"clefable\",\n    \"vulpix\", \"ninetales\", \"jigglypuff\", \"wigglytuff\", \"zubat\", \"golbat\",\n    \"oddish\", \"gloom\", \"vileplume\", \"paras\", \"parasect\", \"venonat\", \"venomoth\",\n    \"diglett\", \"dugtrio\", \"meowth\", \"persian\", \"psyduck\", \"golduck\",\n    \"mankey\", \"primeape\", \"growlithe\", \"arcanine\", \"poliwag\", \"poliwhirl\",\n    \"poliwrath\", \"abra\", \"kadabra\", \"alakazam\", \"machop\", \"machoke\", \"machamp\",\n    \"bellsprout\", \"weepinbell\", \"victreebel\", \"tentacool\", \"tentacruel\",\n    \"geodude\", \"graveler\", \"golem\", \"ponyta\", \"rapidash\", \"slowpoke\", \"slowbro\",\n    \"magnemite\", \"magneton\", \"farfetchd\", \"doduo\", \"dodrio\", \"seel\", \"dewgong\",\n    \"grimer\", \"muk\", \"shellder\", \"cloyster\", \"gastly\", \"haunter\", \"gengar\",\n    \"onix\", \"drowzee\", \"hypno\", \"krabby\", \"kingler\", \"voltorb\", \"electrode\",\n    \"exeggcute\", \"exeggutor\", \"cubone\", \"marowak\", \"hitmonlee\", \"hitmonchan\",\n    \"lickitung\", \"koffing\", \"weezing\", \"rhyhorn\", \"rhydon\", \"chansey\", \"tangela\",\n    \"kangaskhan\", \"horsea\", \"seadra\", \"goldeen\", \"seaking\", \"staryu\", \"starmie\",\n    \"mr-mime\", \"scyther\", \"jynx\", \"electabuzz\", \"magmar\", \"pinsir\", \"tauros\",\n    \"magikarp\", \"gyarados\", \"lapras\", \"ditto\", \"eevee\", \"vaporeon\", \"jolteon\",\n    \"flareon\", \"porygon\", \"omanyte\", \"omastar\", \"kabuto\", \"kabutops\",\n    \"aerodactyl\", \"snorlax\", \"articuno\", \"zapdos\", \"moltres\", \"dratini\",\n    \"dragonair\", \"dragonite\", \"mewtwo\", \"mew\"\n]\n\nPOKEAPI_BASE = \"https://pokeapi.co/api/v2/pokemon\"\n\ndef extract_sprite_urls(sprites):\n    \"\"\"Extract all available sprite URLs.\"\"\"\n    urls = []\n    def add_sprite(url, name):\n        if url and isinstance(url, str):\n            urls.append((url, name))\n    \n    # Main sprites\n    add_sprite(sprites.get('front_default'), 'front_default')\n    add_sprite(sprites.get('back_default'), 'back_default')\n    add_sprite(sprites.get('front_shiny'), 'front_shiny')\n    add_sprite(sprites.get('back_shiny'), 'back_shiny')\n    \n    # Other variants\n    other = sprites.get('other', {})\n    \n    # Dream World\n    dw = other.get('dream_world', {})\n    add_sprite(dw.get('front_default'), 'dream_world')\n    \n    # Home\n    home = other.get('home', {})\n    add_sprite(home.get('front_default'), 'home_front')\n    add_sprite(home.get('front_shiny'), 'home_shiny')\n    \n    # Official artwork\n    art = other.get('official-artwork', {})\n    add_sprite(art.get('front_default'), 'official_artwork')\n    add_sprite(art.get('front_shiny'), 'official_artwork_shiny')\n    \n    # Showdown\n    showdown = other.get('showdown', {})\n    add_sprite(showdown.get('front_default'), 'showdown_front')\n    add_sprite(showdown.get('back_default'), 'showdown_back')\n    \n    # Game versions\n    versions = sprites.get('versions', {})\n    for gen_name, gen_data in versions.items():\n        if isinstance(gen_data, dict):\n            for game, game_sprites in gen_data.items():\n                if isinstance(game_sprites, dict):\n                    short_name = f\"{gen_name.replace('generation-', 'g')}_{game}\"[:20]\n                    add_sprite(game_sprites.get('front_default'), f'{short_name}_f')\n                    add_sprite(game_sprites.get('front_shiny'), f'{short_name}_s')\n    \n    return urls\n\ndef download_pokemon_sprites(pokemon_name, output_dir, session):\n    \"\"\"Download all sprites for a Pokemon.\"\"\"\n    pokemon_dir = output_dir / pokemon_name\n    pokemon_dir.mkdir(parents=True, exist_ok=True)\n    \n    try:\n        response = session.get(f\"{POKEAPI_BASE}/{pokemon_name}\", timeout=30)\n        response.raise_for_status()\n        data = response.json()\n    except Exception as e:\n        print(f\"  Error fetching {pokemon_name}: {e}\")\n        return 0\n    \n    sprites = data.get('sprites', {})\n    sprite_urls = extract_sprite_urls(sprites)\n    downloaded = 0\n    \n    for url, variant in sprite_urls:\n        try:\n            # Skip SVG and check if already exists\n            if url.endswith('.svg'):\n                continue\n            \n            ext = '.png' if not url.endswith('.gif') else '.gif'\n            save_path = pokemon_dir / f\"{pokemon_name}_{variant}{ext}\"\n            \n            if save_path.exists():\n                downloaded += 1\n                continue\n            \n            img_response = session.get(url, timeout=30)\n            img_response.raise_for_status()\n            \n            # Handle GIF -> PNG conversion\n            if url.endswith('.gif'):\n                img = Image.open(BytesIO(img_response.content))\n                if img.mode in ('RGBA', 'P'):\n                    bg = Image.new('RGB', img.size, (255, 255, 255))\n                    if img.mode == 'P':\n                        img = img.convert('RGBA')\n                    bg.paste(img, mask=img.split()[-1] if 'A' in img.mode else None)\n                    img = bg\n                else:\n                    img = img.convert('RGB')\n                save_path = save_path.with_suffix('.png')\n                img.save(save_path, 'PNG')\n            else:\n                with open(save_path, 'wb') as f:\n                    f.write(img_response.content)\n            \n            downloaded += 1\n            time.sleep(0.05)  # Rate limiting\n            \n        except Exception:\n            continue\n    \n    return downloaded\n\ndef augment_image(img, aug_type, target_size=(224, 224)):\n    \"\"\"Apply augmentation to an image.\"\"\"\n    if aug_type == 'original':\n        pass\n    elif aug_type == 'flip':\n        img = ImageOps.mirror(img)\n    elif aug_type == 'rotate_left':\n        img = img.rotate(10, fillcolor=(255, 255, 255))\n    elif aug_type == 'rotate_right':\n        img = img.rotate(-10, fillcolor=(255, 255, 255))\n    elif aug_type == 'bright':\n        img = ImageEnhance.Brightness(img).enhance(1.2)\n    elif aug_type == 'dark':\n        img = ImageEnhance.Brightness(img).enhance(0.8)\n    elif aug_type == 'contrast':\n        img = ImageEnhance.Contrast(img).enhance(1.15)\n    elif aug_type == 'saturate':\n        img = ImageEnhance.Color(img).enhance(1.2)\n    elif aug_type == 'combined_1':\n        img = ImageOps.mirror(img)\n        img = img.rotate(random.uniform(-5, 5), fillcolor=(255, 255, 255))\n        img = ImageEnhance.Brightness(img).enhance(random.uniform(0.9, 1.1))\n    elif aug_type == 'combined_2':\n        img = ImageEnhance.Contrast(img).enhance(random.uniform(0.9, 1.1))\n        img = ImageEnhance.Color(img).enhance(random.uniform(0.9, 1.1))\n    return img\n\ndef resize_with_padding(img, target_size=(224, 224)):\n    \"\"\"Resize image maintaining aspect ratio with padding.\"\"\"\n    # Convert to RGB if needed\n    if img.mode in ('RGBA', 'LA', 'P'):\n        background = Image.new('RGB', img.size, (255, 255, 255))\n        if img.mode == 'P':\n            img = img.convert('RGBA')\n        if 'A' in img.mode:\n            background.paste(img, mask=img.split()[-1])\n        img = background\n    elif img.mode != 'RGB':\n        img = img.convert('RGB')\n    \n    # Calculate new size\n    ratio = min(target_size[0] / img.width, target_size[1] / img.height)\n    new_size = (int(img.width * ratio), int(img.height * ratio))\n    img = img.resize(new_size, Image.LANCZOS)\n    \n    # Create padded image\n    padded = Image.new('RGB', target_size, (255, 255, 255))\n    offset = ((target_size[0] - new_size[0]) // 2, (target_size[1] - new_size[1]) // 2)\n    padded.paste(img, offset)\n    return padded\n\n# Augmentation types\nAUG_TYPES = ['original', 'flip', 'rotate_left', 'rotate_right', 'bright', \n             'dark', 'contrast', 'saturate', 'combined_1', 'combined_2']\n\n# Check if dataset already exists\ndata_path = Path(CONFIG['data_dir'])\nif (data_path / 'pokemon_augmented').exists():\n    aug_dirs = list((data_path / 'pokemon_augmented').iterdir())\n    if len(aug_dirs) >= 150:\n        print(f\"Augmented dataset already exists ({len(aug_dirs)} Pokemon)\")\n        print(\"Skipping generation...\")\n        POKEMON_DIR = data_path / 'pokemon_augmented'\n    else:\n        print(\"Partial dataset found, regenerating...\")\nelse:\n    print(\"=\" * 60)\n    print(\"GENERATING OFFICIAL POKEMON DATASET\")\n    print(\"=\" * 60)\n    \n    # Create directories\n    official_dir = data_path / 'pokemon_official'\n    augmented_dir = data_path / 'pokemon_augmented'\n    official_dir.mkdir(parents=True, exist_ok=True)\n    augmented_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Create session\n    session = requests.Session()\n    session.headers.update({'User-Agent': 'PokemonClassifier/1.0'})\n    \n    # Download sprites\n    print(\"\\nStep 1: Downloading official sprites from PokeAPI...\")\n    for i, pokemon in enumerate(GEN1_POKEMON):\n        print(f\"[{i+1:3d}/151] {pokemon}...\", end=\" \")\n        count = download_pokemon_sprites(pokemon, official_dir, session)\n        print(f\"{count} sprites\")\n        time.sleep(0.3)  # Rate limiting\n    \n    # Augment images\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Step 2: Augmenting images...\")\n    print(\"=\" * 60)\n    \n    total_augmented = 0\n    for i, pokemon in enumerate(GEN1_POKEMON):\n        pokemon_in = official_dir / pokemon\n        pokemon_out = augmented_dir / pokemon\n        pokemon_out.mkdir(parents=True, exist_ok=True)\n        \n        if not pokemon_in.exists():\n            continue\n        \n        images = list(pokemon_in.glob('*.png')) + list(pokemon_in.glob('*.jpg'))\n        aug_count = 0\n        \n        for img_path in images:\n            try:\n                img = Image.open(img_path)\n                img = resize_with_padding(img)\n                \n                for aug_type in AUG_TYPES:\n                    aug_img = augment_image(img.copy(), aug_type)\n                    out_name = f\"{img_path.stem}_{aug_type}.jpg\"\n                    aug_img.save(pokemon_out / out_name, 'JPEG', quality=95)\n                    aug_count += 1\n            except Exception:\n                continue\n        \n        total_augmented += aug_count\n        print(f\"[{i+1:3d}/151] {pokemon}: {aug_count} images\")\n    \n    print(f\"\\nTotal augmented images: {total_augmented}\")\n    POKEMON_DIR = augmented_dir\n\n# Generate labels\nclass_names = sorted([d.name for d in POKEMON_DIR.iterdir() if d.is_dir()])\nlabels = {\n    'class_names': class_names,\n    'class_indices': {name: i for i, name in enumerate(class_names)},\n    'index_to_class': {str(i): name for i, name in enumerate(class_names)},\n    'num_classes': len(class_names)\n}\nwith open(POKEMON_DIR / 'labels.json', 'w') as f:\n    json.dump(labels, f, indent=2)\n\n# Count images\ntotal = sum(len(list((POKEMON_DIR / p).glob('*.jpg')) + list((POKEMON_DIR / p).glob('*.png'))) \n            for p in class_names if (POKEMON_DIR / p).exists())\nprint(f\"\\nDataset ready:\")\nprint(f\"  Location: {POKEMON_DIR}\")\nprint(f\"  Pokemon classes: {len(class_names)}\")\nprint(f\"  Total images: {total}\")\nprint(f\"  Avg per class: {total/len(class_names):.1f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Explore Dataset\n",
    "#@markdown Visualize sample images and class distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Find Pokemon directories\n",
    "data_path = Path(CONFIG['data_dir'])\n",
    "\n",
    "# Try to find the directory containing Pokemon folders\n",
    "pokemon_dir = None\n",
    "for item in data_path.iterdir():\n",
    "    if item.is_dir():\n",
    "        subdirs = list(item.iterdir())\n",
    "        if len([d for d in subdirs if d.is_dir()]) > 50:\n",
    "            pokemon_dir = item\n",
    "            break\n",
    "\n",
    "if pokemon_dir is None:\n",
    "    # Data might be directly in data_dir\n",
    "    pokemon_dir = data_path\n",
    "\n",
    "class_dirs = sorted([d for d in pokemon_dir.iterdir() if d.is_dir()])\n",
    "print(f\"Found {len(class_dirs)} Pokemon classes\")\n",
    "\n",
    "# Count images per class\n",
    "class_counts = {}\n",
    "for class_dir in class_dirs:\n",
    "    images = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\"))\n",
    "    class_counts[class_dir.name] = len(images)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "counts = list(class_counts.values())\n",
    "plt.hist(counts, bins=20, edgecolor='black')\n",
    "plt.xlabel('Images per class')\n",
    "plt.ylabel('Number of classes')\n",
    "plt.title('Class Distribution')\n",
    "plt.axvline(np.mean(counts), color='r', linestyle='--', label=f'Mean: {np.mean(counts):.1f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Min images: {min(counts)}\")\n",
    "print(f\"  Max images: {max(counts)}\")\n",
    "print(f\"  Mean images: {np.mean(counts):.1f}\")\n",
    "print(f\"  Median images: {np.median(counts):.1f}\")\n",
    "\n",
    "# Show sample images\n",
    "fig, axes = plt.subplots(4, 6, figsize=(15, 10))\n",
    "sample_classes = random.sample(class_dirs, 24)\n",
    "\n",
    "for ax, class_dir in zip(axes.flat, sample_classes):\n",
    "    images = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.png\"))\n",
    "    if images:\n",
    "        img = Image.open(random.choice(images))\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(class_dir.name[:12], fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Pokemon Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Store for later use\n",
    "POKEMON_DIR = pokemon_dir\n",
    "CLASS_NAMES = sorted([d.name for d in class_dirs])\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(f\"\\nFound {NUM_CLASSES} Pokemon classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Prepare Data Generators\n",
    "#@markdown Create train/validation/test splits with augmentation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=CONFIG['rotation_range'],\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=CONFIG['zoom_range'],\n",
    "    horizontal_flip=CONFIG['horizontal_flip'],\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    fill_mode='nearest',\n",
    "    validation_split=CONFIG['validation_split'] + CONFIG['test_split']  # Combined for initial split\n",
    ")\n",
    "\n",
    "# Validation/test data generator (no augmentation)\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=CONFIG['test_split'] / (CONFIG['validation_split'] + CONFIG['test_split'])  # Split val from test\n",
    ")\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    POKEMON_DIR,\n",
    "    target_size=(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# For validation and test, we need a workaround since ImageDataGenerator \n",
    "# only supports 2-way split. We'll use the validation subset and split it.\n",
    "temp_val_generator = train_datagen.flow_from_directory(\n",
    "    POKEMON_DIR,\n",
    "    target_size=(CONFIG['image_size'], CONFIG['image_size']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# For simplicity in this notebook, we'll use the same data for val and test\n",
    "# In production, you'd want a proper 3-way split\n",
    "val_generator = temp_val_generator\n",
    "test_generator = temp_val_generator\n",
    "\n",
    "# Store class indices\n",
    "class_indices = train_generator.class_indices\n",
    "index_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "print(f\"Data generators created\")\n",
    "print(f\"  Training samples: {train_generator.samples}\")\n",
    "print(f\"  Validation samples: {val_generator.samples}\")\n",
    "print(f\"  Number of classes: {train_generator.num_classes}\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Steps per epoch: {len(train_generator)}\")\n",
    "\n",
    "# Save class mapping\n",
    "import json\n",
    "labels_path = Path(CONFIG['models_dir']) / 'labels.json'\n",
    "with open(labels_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'class_names': list(class_indices.keys()),\n",
    "        'class_indices': class_indices,\n",
    "        'index_to_class': index_to_class,\n",
    "        'num_classes': len(class_indices)\n",
    "    }, f, indent=2)\n",
    "print(f\"  Labels saved to: {labels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Visualize Augmentations\n",
    "#@markdown See how training augmentations transform images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a sample batch\n",
    "sample_batch = next(train_generator)\n",
    "images, labels = sample_batch\n",
    "\n",
    "# Show augmented images\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(images):\n",
    "        ax.imshow(images[i])\n",
    "        class_idx = np.argmax(labels[i])\n",
    "        ax.set_title(index_to_class[class_idx][:15], fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Augmented Training Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reset generator\n",
    "train_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6. Build Model Architecture\n",
    "#@markdown Create MobileNetV3 with custom classification head\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, GlobalAveragePooling2D, \n",
    "    BatchNormalization, Input\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(num_classes, image_size=224, dropout_rate=0.5):\n",
    "    \"\"\"Build MobileNetV3 with custom classification head.\"\"\"\n",
    "    \n",
    "    # Load pre-trained MobileNetV3\n",
    "    base_model = MobileNetV3Small(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = Input(shape=(image_size, image_size, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Build the model\n",
    "model, base_model = build_model(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    image_size=CONFIG['image_size'],\n",
    "    dropout_rate=CONFIG['dropout_rate']\n",
    ")\n",
    "\n",
    "# Compile for Stage 1 (frozen base)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['learning_rate_frozen']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_accuracy')]\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\nModel built\")\n",
    "print(f\"  Total parameters: {model.count_params():,}\")\n",
    "print(f\"  Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7. Define Training Callbacks\n",
    "#@markdown Set up checkpointing, early stopping, and learning rate scheduling\n",
    "\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,\n",
    "    TensorBoard, CSVLogger\n",
    ")\n",
    "import datetime\n",
    "\n",
    "# Create directories for logs\n",
    "log_dir = Path(CONFIG['models_dir']) / 'logs' / datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    # Save best model\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(Path(CONFIG['models_dir']) / 'best_model.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=CONFIG['early_stopping_patience'],\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate when stuck\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=CONFIG['reduce_lr_patience'],\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    TensorBoard(\n",
    "        log_dir=str(log_dir),\n",
    "        histogram_freq=1\n",
    "    ),\n",
    "    \n",
    "    # CSV logging\n",
    "    CSVLogger(\n",
    "        str(Path(CONFIG['models_dir']) / 'training_log.csv'),\n",
    "        append=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Callbacks configured\")\n",
    "print(f\"  Checkpoints: {CONFIG['models_dir']}/best_model.keras\")\n",
    "print(f\"  TensorBoard logs: {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 8. Stage 1: Train Classification Head (Frozen Base)\n",
    "#@markdown Train only the new classification layers\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STAGE 1: Training classification head (base model frozen)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history_frozen = model.fit(\n",
    "    train_generator,\n",
    "    epochs=CONFIG['epochs_frozen'],\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_frozen.history['accuracy'], label='Train')\n",
    "axes[0].plot(history_frozen.history['val_accuracy'], label='Validation')\n",
    "axes[0].set_title('Stage 1: Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_frozen.history['loss'], label='Train')\n",
    "axes[1].plot(history_frozen.history['val_loss'], label='Validation')\n",
    "axes[1].set_title('Stage 1: Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(Path(CONFIG['models_dir']) / 'stage1_training.png'))\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStage 1 complete\")\n",
    "print(f\"  Final train accuracy: {history_frozen.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  Final val accuracy: {history_frozen.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 9. Stage 2: Fine-tune Base Model\n",
    "#@markdown Unfreeze top layers and continue training with lower learning rate\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STAGE 2: Fine-tuning (unfreezing top layers)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Unfreeze the top layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except the top N\n",
    "for layer in base_model.layers[:-CONFIG['unfreeze_layers']]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['learning_rate_unfrozen']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_accuracy')]\n",
    ")\n",
    "\n",
    "# Print trainable status\n",
    "trainable_count = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "print(f\"Trainable parameters after unfreezing: {trainable_count:,}\")\n",
    "\n",
    "# Continue training\n",
    "history_unfrozen = model.fit(\n",
    "    train_generator,\n",
    "    epochs=CONFIG['epochs_unfrozen'],\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_unfrozen.history['accuracy'], label='Train')\n",
    "axes[0].plot(history_unfrozen.history['val_accuracy'], label='Validation')\n",
    "axes[0].set_title('Stage 2: Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_unfrozen.history['loss'], label='Train')\n",
    "axes[1].plot(history_unfrozen.history['val_loss'], label='Validation')\n",
    "axes[1].set_title('Stage 2: Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(Path(CONFIG['models_dir']) / 'stage2_training.png'))\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStage 2 complete\")\n",
    "print(f\"  Final train accuracy: {history_unfrozen.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  Final val accuracy: {history_unfrozen.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 10. Evaluate on Test Set\n",
    "#@markdown Get final performance metrics\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best model\n",
    "best_model = tf.keras.models.load_model(\n",
    "    str(Path(CONFIG['models_dir']) / 'best_model.keras')\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_generator.reset()\n",
    "results = best_model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {results[0]:.4f}\")\n",
    "print(f\"  Top-1 Accuracy: {results[1]:.4f} ({results[1]*100:.1f}%)\")\n",
    "print(f\"  Top-5 Accuracy: {results[2]:.4f} ({results[2]*100:.1f}%)\")\n",
    "\n",
    "# Check if we hit our target\n",
    "if results[1] >= 0.80:\n",
    "    print(f\"\\nSUCCESS! Achieved {results[1]*100:.1f}% accuracy (target: 80%)\")\n",
    "else:\n",
    "    print(f\"\\nBelow target. Achieved {results[1]*100:.1f}% (target: 80%)\")\n",
    "    print(\"   Consider: more epochs, data augmentation, or larger model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 11. Confusion Matrix & Error Analysis\n",
    "#@markdown Understand where the model makes mistakes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions\n",
    "test_generator.reset()\n",
    "predictions = best_model.predict(test_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report (showing worst performing classes):\\n\")\n",
    "report = classification_report(\n",
    "    true_classes, \n",
    "    predicted_classes, \n",
    "    target_names=list(class_indices.keys()),\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Find worst performing classes\n",
    "class_f1_scores = {k: v['f1-score'] for k, v in report.items() \n",
    "                   if k not in ['accuracy', 'macro avg', 'weighted avg']}\n",
    "worst_classes = sorted(class_f1_scores.items(), key=lambda x: x[1])[:10]\n",
    "\n",
    "print(\"Worst performing Pokemon:\")\n",
    "for name, f1 in worst_classes:\n",
    "    print(f\"  {name}: F1={f1:.3f}\")\n",
    "\n",
    "# Confusion matrix for worst classes\n",
    "worst_indices = [class_indices[name] for name, _ in worst_classes]\n",
    "mask = np.isin(true_classes, worst_indices)\n",
    "cm_subset = confusion_matrix(\n",
    "    true_classes[mask], \n",
    "    predicted_classes[mask],\n",
    "    labels=worst_indices\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm_subset, \n",
    "    annot=True, \n",
    "    fmt='d',\n",
    "    xticklabels=[worst_classes[i][0][:10] for i in range(len(worst_classes))],\n",
    "    yticklabels=[worst_classes[i][0][:10] for i in range(len(worst_classes))],\n",
    "    cmap='Blues'\n",
    ")\n",
    "plt.title('Confusion Matrix (Worst Performing Classes)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(Path(CONFIG['models_dir']) / 'confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "# Show misclassified examples\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Sample Misclassified Images\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
    "sample_mistakes = np.random.choice(misclassified_indices, min(9, len(misclassified_indices)), replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "test_generator.reset()\n",
    "all_images = []\n",
    "for i in range(len(test_generator)):\n",
    "    batch = next(test_generator)\n",
    "    all_images.extend(batch[0])\n",
    "    if len(all_images) >= len(true_classes):\n",
    "        break\n",
    "\n",
    "for ax, idx in zip(axes.flat, sample_mistakes):\n",
    "    if idx < len(all_images):\n",
    "        ax.imshow(all_images[idx])\n",
    "        true_name = index_to_class[true_classes[idx]]\n",
    "        pred_name = index_to_class[predicted_classes[idx]]\n",
    "        conf = predictions[idx][predicted_classes[idx]]\n",
    "        ax.set_title(f\"True: {true_name[:12]}\\nPred: {pred_name[:12]} ({conf:.2f})\", fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Misclassified Examples', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(Path(CONFIG['models_dir']) / 'misclassified_examples.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 12. Export Model for Browser (TensorFlow.js)\n",
    "#@markdown Convert model to TensorFlow.js format with quantization\n",
    "\n",
    "import tensorflowjs as tfjs\n",
    "from pathlib import Path\n",
    "\n",
    "# Export directory\n",
    "tfjs_dir = Path(CONFIG['models_dir']) / 'tfjs_model'\n",
    "tfjs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert to TensorFlow.js with quantization\n",
    "print(\"Converting to TensorFlow.js format...\")\n",
    "tfjs.converters.save_keras_model(\n",
    "    best_model,\n",
    "    str(tfjs_dir),\n",
    "    quantization_dtype_map={'uint8': '*'}  # Quantize all layers to uint8\n",
    ")\n",
    "\n",
    "# Check output size\n",
    "total_size = sum(f.stat().st_size for f in tfjs_dir.glob('**/*') if f.is_file())\n",
    "print(f\"\\nModel exported to: {tfjs_dir}\")\n",
    "print(f\"  Total size: {total_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# List files\n",
    "print(\"\\nExported files:\")\n",
    "for f in sorted(tfjs_dir.glob('*')):\n",
    "    size = f.stat().st_size / 1024\n",
    "    print(f\"  {f.name}: {size:.1f} KB\")\n",
    "\n",
    "# Copy labels.json to tfjs directory\n",
    "import shutil\n",
    "shutil.copy(\n",
    "    Path(CONFIG['models_dir']) / 'labels.json',\n",
    "    tfjs_dir / 'labels.json'\n",
    ")\n",
    "print(f\"  labels.json: copied\")\n",
    "\n",
    "# Create a zip for easy download\n",
    "!cd {CONFIG['models_dir']} && zip -r tfjs_model.zip tfjs_model/\n",
    "print(f\"\\nCreated tfjs_model.zip for download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 13. Get Download Link (Recommended for Mobile)\n",
    "#@markdown Upload model to transfer.sh and get a shareable link\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UPLOAD TO TRANSFER.SH\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\")\n",
    "print(\"This uploads your model to transfer.sh and gives you a link.\")\n",
    "print(\"The link works on any device (phone, tablet, computer).\")\n",
    "print(\"\")\n",
    "\n",
    "zip_path = Path(CONFIG['models_dir']) / 'tfjs_model.zip'\n",
    "\n",
    "if zip_path.exists():\n",
    "    file_size = zip_path.stat().st_size / 1024 / 1024\n",
    "    print(f\"Uploading tfjs_model.zip ({file_size:.2f} MB)...\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Upload to transfer.sh using curl\n",
    "    result = subprocess.run(\n",
    "        ['curl', '--upload-file', str(zip_path), 'https://transfer.sh/tfjs_model.zip'],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0 and result.stdout.startswith('https://'):\n",
    "        download_url = result.stdout.strip()\n",
    "        print(\"=\" * 60)\n",
    "        print(\"SUCCESS! Your download link:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\")\n",
    "        print(f\"  {download_url}\")\n",
    "        print(\"\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\")\n",
    "        print(\"Instructions:\")\n",
    "        print(\"  1. Copy the link above\")\n",
    "        print(\"  2. Open it in any browser (phone, computer, etc.)\")\n",
    "        print(\"  3. The file will download automatically\")\n",
    "        print(\"\")\n",
    "        print(\"Note: Link expires in 14 days.\")\n",
    "        \n",
    "        # Store the URL for reference\n",
    "        DOWNLOAD_URL = download_url\n",
    "    else:\n",
    "        print(\"Upload failed. Error:\")\n",
    "        print(result.stderr if result.stderr else result.stdout)\n",
    "        print(\"\")\n",
    "        print(\"Try the browser download option (Cell 14) instead.\")\n",
    "else:\n",
    "    print(\"Model zip not found. Run cell 12 first to export the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 14. Browser Download (Alternative)\n",
    "#@markdown Download directly through Colab (works best on desktop)\n",
    "\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BROWSER DOWNLOAD\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\")\n",
    "print(\"This triggers a browser download.\")\n",
    "print(\"Works best on desktop. May be unreliable on mobile.\")\n",
    "print(\"\")\n",
    "\n",
    "# Download the zip file\n",
    "zip_path = Path(CONFIG['models_dir']) / 'tfjs_model.zip'\n",
    "if zip_path.exists():\n",
    "    print(\"Downloading tfjs_model.zip...\")\n",
    "    files.download(str(zip_path))\n",
    "    print(\"\")\n",
    "    print(\"Download started! Check your browser's download folder.\")\n",
    "else:\n",
    "    print(\"Model zip not found. Run the export cell first.\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"The zip file contains:\")\n",
    "print(\"  - model.json (model architecture)\")\n",
    "print(\"  - group1-shard*.bin (model weights)\")\n",
    "print(\"  - labels.json (class name mapping)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 15. Download Keras Model (Optional)\n",
    "#@markdown Download the full Keras model for further training\n",
    "\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "# Download Keras model\n",
    "keras_path = Path(CONFIG['models_dir']) / 'best_model.keras'\n",
    "if keras_path.exists():\n",
    "    print(\"Downloading best_model.keras...\")\n",
    "    files.download(str(keras_path))\n",
    "    print(\"\")\n",
    "    print(\"This is the full Keras model. Use it if you want to:\")\n",
    "    print(\"  - Continue training later\")\n",
    "    print(\"  - Export to other formats (ONNX, TFLite, etc.)\")\n",
    "    print(\"  - Run inference in Python\")\n",
    "else:\n",
    "    print(\"Keras model not found. Training may not have completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 16. Test Inference\n",
    "#@markdown Verify the exported model works correctly\n",
    "\n",
    "# Test with a sample image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Get a sample image\n",
    "test_generator.reset()\n",
    "sample_batch = next(test_generator)\n",
    "sample_image = sample_batch[0][0]\n",
    "sample_label = np.argmax(sample_batch[1][0])\n",
    "\n",
    "# Run inference\n",
    "prediction = best_model.predict(np.expand_dims(sample_image, 0), verbose=0)\n",
    "predicted_class = np.argmax(prediction[0])\n",
    "confidence = prediction[0][predicted_class]\n",
    "\n",
    "# Get top 5 predictions\n",
    "top5_indices = np.argsort(prediction[0])[-5:][::-1]\n",
    "top5_probs = prediction[0][top5_indices]\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(sample_image)\n",
    "plt.title(f\"True: {index_to_class[sample_label]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pos = np.arange(5)\n",
    "plt.barh(y_pos, top5_probs)\n",
    "plt.yticks(y_pos, [index_to_class[i][:15] for i in top5_indices])\n",
    "plt.xlabel('Confidence')\n",
    "plt.title('Top 5 Predictions')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInference test complete\")\n",
    "print(f\"  Predicted: {index_to_class[predicted_class]} ({confidence:.2%})\")\n",
    "print(f\"  Actual: {index_to_class[sample_label]}\")\n",
    "correct_symbol = 'Correct' if predicted_class == sample_label else 'Incorrect'\n",
    "print(f\"  Result: {correct_symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 17. Summary & Next Steps\n",
    "#@markdown Review what was accomplished and plan next steps\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load training log\n",
    "import pandas as pd\n",
    "log_path = Path(CONFIG['models_dir']) / 'training_log.csv'\n",
    "if log_path.exists():\n",
    "    log_df = pd.read_csv(log_path)\n",
    "    best_epoch = log_df['val_accuracy'].idxmax()\n",
    "    best_val_acc = log_df['val_accuracy'].max()\n",
    "    \n",
    "    print(f\"\\nTraining Results:\")\n",
    "    print(f\"  Best validation accuracy: {best_val_acc:.4f} ({best_val_acc*100:.1f}%)\")\n",
    "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
    "    print(f\"  Total epochs trained: {len(log_df)}\")\n",
    "\n",
    "print(f\"\\nExported Model:\")\n",
    "tfjs_dir = Path(CONFIG['models_dir']) / 'tfjs_model'\n",
    "if tfjs_dir.exists():\n",
    "    total_size = sum(f.stat().st_size for f in tfjs_dir.glob('**/*') if f.is_file())\n",
    "    print(f\"  Location: {tfjs_dir}\")\n",
    "    print(f\"  Size: {total_size / 1024 / 1024:.2f} MB\")\n",
    "    print(f\"  Format: TensorFlow.js (quantized)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DOWNLOAD OPTIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\")\n",
    "print(\"Choose one of these options to get your model:\")\n",
    "print(\"\")\n",
    "print(\"  Option 1: Transfer.sh link (Cell 13)\")\n",
    "print(\"    - Best for mobile users\")\n",
    "print(\"    - Get a link you can open anywhere\")\n",
    "print(\"    - Link expires in 14 days\")\n",
    "print(\"\")\n",
    "print(\"  Option 2: Browser download (Cell 14)\")\n",
    "print(\"    - Best for desktop users\")\n",
    "print(\"    - Direct download to your computer\")\n",
    "print(\"\")\n",
    "\n",
    "# Show the download URL if it was generated\n",
    "if 'DOWNLOAD_URL' in dir():\n",
    "    print(\"Your transfer.sh link:\")\n",
    "    print(f\"  {DOWNLOAD_URL}\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Day 2: Browser Integration\n",
    "  1. Extract tfjs_model.zip\n",
    "  2. Create React/Next.js app\n",
    "  3. Load model with TensorFlow.js\n",
    "  4. Add camera capture\n",
    "  5. Build Pokedex UI\n",
    "\n",
    "Day 3+: Improvements\n",
    "  - Create benchmark dataset\n",
    "  - Add Pokemon card images to training data\n",
    "  - Test on real-world photos\n",
    "  - Iterate based on failures\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}